[["regulation-of-ai.html", "Chapter 6 Regulation of AI 6.1 Current regulation 6.2 Proposed regulation 6.3 Regulation as a competitive advantage", " Chapter 6 Regulation of AI AI technology has been making major advances with AI systems, such as ChatGPT, being used by over 40% of college students in the United States (Balderson, 2023). Companies and organizations all around the world are increasing their use of AI to gain a competitive advantage in their respective industries. This race of AI technology is putting focus on what regulation needs to be developed to control these advances. AI is becoming a core part of political discourse, and big names in the tech industry such as Steve Wozniak, Elon Musk, and politicians such as Andrew Yang, have signed an open letter asking for a moratorium on AI experimentation for regulation development (Pause Giant AI experiments: An open letter, 2023). While this open letter has not led to any action, it does bring attention to the fact that governments will have to focus a large part of their future legislation on regulation. AI systems and regulations are global and inter-industry issues. There are so many different pieces, in different industries, and they’re all moving at different paces, which makes it difficult to legislate. 6.1 Current regulation Governments around the world have only scratched the surface on legislating AI regulation. Most countries, like the United States, are still debating what parts of AI should be regulated, and how much regulation is appropriate. There are a few exceptions to this trend. The European Parliament has recently taken its first step to legal regulation by passing a draft law named the AI Act. This act will focus on limiting the most high-risk parts of AI technology, such as facial recognition. It will also force upcoming AI systems to be more open about the data they are using. While this is only a draft law, the final version of this law is expected to be passed by the end of 2023, making it one of the first large steps toward government-enforced AI regulation (Satariano, 2023). 6.2 Proposed regulation AI regulations are slowly starting to be put into effect, but there are still so many questions on how it will work. The CEO of OpenAI, Sam Altman, wrote a testimony to the Senate this May asking that they start strongly considering regulating artificial intelligence (Hendrix, 2023). He proposed solutions such as licensing companies to use AI, or creating a government agency strictly responsible for AI regulation. Altman’s solutions were questioned by some, though, as there are still many disagreements about what the best way to legislate AI should be. While these solutions seem good on paper, the answer to how to regulate AI is not that simple. Officials are predicting that AI regulation agencies have the potential of being compromised. Having only one small sector of government responsible for such a broad and important issue could lead to bias. Experts have recommended that AI needs to be diversely regulated by a combination of different agencies and organizations. They have said that regulation should be created by a collaboration from academia, policy experts, industry experts, and even international agencies (Susarla, 2023). New strategies for AI regulation are being proposed regularly by CEOs and other big names in the tech field. AI technology is progressing rapidly and there is an understanding of the need to regulate it before it gets bigger, faster, and stronger. While most tech officials are in agreement about the importance of regulation, government officials can often be harder to come by. The median age of the U.S. The House of Representatives is 58 years old, and the median age is 65 years old in the Senate. The United States lawmaker demographic is much older than the mean age in America (38 years old) (Blazina and DeSilver, 2023). Their age could mean they have lesser knowledge or insight into these new technological advancements than young, up-and-coming workers in the tech industry do. The lawmakers’ lack of understanding of artificial intelligence applications can lead to more debate than needed on what type of regulation should be established. These are prime years to establish effective regulations on artificial intelligence and how it is used. Setting regulations now, when AI is not overwhelmingly powerful, could be key to getting a grasp on this technology and its future that we cannot predict. Some places, like the European Union, are taking their first steps toward government action, but others, like the United States, have barely scratched the surface. While companies are already beginning to integrate AI regulation into their business, not every organization will follow suit without government intervention. AI Regulation should be expected to be a hot topic in government and politics in the near future since AI will continue to progress and the demand for regulation will increase with it. 6.3 Regulation as a competitive advantage AI use within companies is becoming increasingly normalized in numerous industries - leading to a higher mistrust in AI and AI regulation among customers and employees of these companies. So much of what artificial intelligence is can be difficult for the average individual to grasp. For some people, the first thing they think of when they hear “AI” is horror stories of technology taking over the world. Acknowledging these individuals and understanding their views is a step that some companies have already started to take. 6.3.1 Pros Responsible AI is a process that certain companies have acquired to regulate their own use of AI. It is the process of developing AI systems that minimizes biases, enforces data security, ensures transparency within companies, and creates opportunities for employees to speak out on their concerns on AI use. Companies using this form of AI regulation have actually found that it can be used as a competitive advantage. Currently, 36% of organizations have said they believe it will create opportunities for competitive differentiation (Eitel-Porter, 2023). The ability to deliver trustworthy AI systems that are regulation-ready can help a company attract new customers because they are using AI safely and are being transparent about its use. While this is a step in the right direction, AI regulation needs to be supported by governments to truly make a difference. 6.3.2 Cons While there are obvious benefits to regulating the use of AI, there are also a number of setbacks that could have a negative effect. Limiting its capabilities or room for growth could lead to artificial intelligence not having the ability or flexibility to adapt or learn in positive ways. Strict regulations could restrain creativity and innovation, and lessen the amount of risks taken by companies. This also could become a problem in relation to international affairs. Companies within countries that set stricter regulations will suffer in comparison to companies rooted in countries that have more flexible AI control (Balderson, 2023). "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
